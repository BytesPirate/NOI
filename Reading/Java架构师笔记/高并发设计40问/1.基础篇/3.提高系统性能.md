# 提高系统性能

- 高并发系统设计的三大目标：高性能、高可用、可拓展

## 高并发

- 是指运用设计手段让系统能够处理更多用户的并发请求，也就是承担更大的流量。**是一切架构设计的背景和前提**
- **性能和可用性**，是我们实现高并发系统设计必须考虑的因素
- **可拓展性**，同样是高并发系统设计必须考虑的因素

## 性能优化原则

1. 性能优化一定不能盲目，一定是问题导向的：脱离了问题，盲目地提早优化会增加系统的复杂度，浪费开发人员的时间，也因为某些优化可能会对业务上有些折中的考虑，所以也会损伤业务。
2. 性能优化也遵循“八二原则”：即可以用20%的精力去解决80%的性能问题，所以在优化的过程中一定要抓住主要矛盾，优先优化主要的性能瓶颈点。
3. 性能优化也要有数据支撑：在优化的过程中，要时刻了解优化让响应时间减少了多少，提升了多少的吞吐量。
4. 性能优化的过程是持续的：高并发的系统通常是业务逻辑相对复杂的系统，那么在这类系统中出现的性能问题通常也会有多方面的原因。因此，我们在做性能优化的时候要明确目标，比方说，支撑每秒 1 万次请求的吞吐量下响应时间在 10ms，那么我们就需要持续不断地寻找性能瓶颈，制定优化方案，直到达到目标为止。

## 性能的度量指标

对于性能我们需要有度量的标准，有了数据才能明确目前存在的性能问题，也能够用数据来评估性能优化的效果。所以，**明确性能的度量指标十分重要**。

一般来说，度量性能的指标是**系统接口的响应时间**，但是单次的响应时间是没有意义的，我们需要知道一段时间性能情况是什么样的。所以，我们需要收集这段时间的响应时间数据，依据一些统计方法计算出**特征值**，这些特征值就能够代表这段时间的性能情况，常见的性能值有以下几列：

- 平均值：平均值就是把这段时间所有请求的响应时间数据相加，再除以总请求数。平均值可以在一定程度上反应这段时间的性能，但是它的**敏感度较差**，如哦这段时间有少量慢请求时，在平均值上并不能如实反应。举个例子，假设我们在`30s`内有`10000`次请求，每次请求的响应时间都是`1ms`，那么这段时间响应时间平均值也是`1ms`。这时，当其中`100`次请求的响应时间变成了`100ms`，那么整体的响应时间是`100 * 100 + 9900 * 1) / 10000 = 1.99ms`。你看，虽然从平均值上来看仅仅增加了不到`1ms`，但是实际情况是有`1%`的请求`（100/10000）`的响应时间已经增加了`100`倍。 所以，平均值对于度量性能来说只能作为一个参考。
- 最大值：就是这段时间内所请求响应时间最长的那个值，它的**问题在于太过于敏感**了，拿上面的例子来说，如果`10000`次请求中只有一次请求的响应时间达到`100ms`，那么这段时间请求的响应耗时的最大值就是`100ms`，性能损耗为原先的百分之一，这种说法明显是不准确的。
- 分位值：分位值有很多种，比如`90`分位、`95`分位、`75`分位。以`90`分位为例，我们把这段时间请求的 响应时间从小到大排序，假如一共有`100`个请求，那么排在第`90`位的响应时间就是`90`分位值。分位值排除了偶发极慢请求对于数据的影响，能够很好地反应这段时间的性能情况，**分位值越大，对于慢请求的影响就越敏感**。

**分位值是最适合作为时间段内，响应时间统计值来使用的**，在实际工作中也应用最多。除此之外，平均值也可以作为一个参考值来使用。

**脱离了并发来谈性能是没有意义的**，我们通常使用**吞吐量**或者**同时在线用户数**来度量并发和流量，使用吞吐量的情况会更多一些。但是，这两个指标是呈倒数关系的。

这是很好理解的，响应时间1s，吞吐量是每秒一次，响应时间缩短到10ms，那么吞吐量就上升到每秒一百次，所以，一般我们度量性能时都会同时兼顾吞吐量和响应时间，比如我们设立性能优化的目标时通常会这样表述：在每秒一万次的请求量下，响应时间在99分位值在10ms以下。

响应时间的控制，这个是不能一概而论的。

从用户使用体验的角度来看：

- `200ms`是第一个分界点：接口的响应时间在`200ms`之内，用户是感受不到延迟的，就像瞬时发生的一样
- `1s`是另一个分界点：接口的响应时间在`1s`之内时，虽然用户可以感受到一些延迟，但却是可以接受的
- 超过`1s`之后用户就会有明显等待的感觉，等待的时间越长，用户的使用体验就越差、

所以，健康系统的`99`分位值的响应时间通常需要控制在`200ms`之内，而不超过`1s`的请求占比要在99.99%以上

## 高并发下的性能优化

主要有两种思路：

- 一种是提高系统的处理核心数
- 一种是减少单次任务的响应时间

### 提高系统的处理核心数

提高系统的处理核心数就是，**增加系统的并行处理能力**，这个思路是优化性能最简单的路径。以上一个例子来说，可以把系统的处理核心增加为两个，并且增加一个进程，让这两个进程跑在不同的核心上。这样从理论上，系统的吞吐量就可以增加一倍。当然，在这种情况下，吞吐量和响应时间就不是倒数关系了，而是 $\text{吞吐量} = \frac{\text{并发进程数}}{\text{响应时间}}$

计算机领域的阿姆达尔定律，它描述了并发进程数与响应时间之间的关系，含义是在固定负载下，并行计算的加速比，也就是并行化之后效率提升情况，可以用下面公式来表示： $\frac{(W_S + W_p)}{(W_s + \frac{W_p}{s})}$

- $W_s$ ：表示任务中的串行计算量
- $W_p$ ：表示任务中的并行计算量
- $s$ ：表示并行进程数

从这个公式我们可以推到出另外一个公式： $\frac{1}{1 - p + \frac{p}{s}}$

其中，`s`还是表示并行进程数，`p`表示任务中并行部分的占比。当`p`为`1`时，也就是完全并行时，加速比与并行进程数相等；当`p`为`0`时，即完全串行时，加速比为 1，也就是说完全无加速；当`s`趋近于无穷大的时候，加速比就等于`1/(1-p)`，你可以看到它完全和`p`成正比。特别是，当`p`为`1`时，加速比趋近于无穷大。
